# dwv references are using the datawave-helm-chart repo resources unless otherwise indicated
global:
  services:
    # use embedded configuration service
    configuration: ingest-configuration
    # use embedded rabbitmq
    rabbitmq: ingest-rabbitmq
    # use dwv zookeeper
    zookeeper: zookeeper
  secrets:
    accumulo:
      name: accumulo
      username: username
      password: password
    keystore:
      name: keystore
      alias: alias
      path: path
      password: password
    truststore:
      name: truststore
      path: path
      password: password
  volumes:
    pki:
      name: pki
      destination: /data/certs
      readOnly: true
      source:
        type: secret
        name: datawave-certificates-secret
    hadoop:
      name: hadoop
      destination: /etc/hadoop/conf
      readOnly: true
      source:
        type: configmap
        # use dwv hadoop config
        name: dwv-hadoop-config
    logs:
      name: logs
      destination: /logs
      source:
        type: hostPath
        path: /srv/logs
    datawave:
      name: datawave-conf
      destination: /etc/datawave/conf
      source:
        type: pvc
        claim: datawave-ingest-config-pvc
        readOnly: true
    output:
      # REQUIRED Output location volume name
      name: output
      # REQUIRED mount location for output
      destination: /output
      # REQUIRED hdfs prefix for destination
      prefix: "file://"
      source:
        # REQUIRED must be one of secret/configmap/hostPath
        type: hostPath
        # REQUIRED when specifying hostPath, host path to mount into destination
        path: /srv/data/datawave/ingest/
    # REQUIRED (Bundler)
    input:
      # REQUIRED input location volume
      name: input
      # REQUIRED mount location for input
      destination: /input
      source:
        # REQUIRED must be one of secret/configmap/hostPath
        type: hostPath
        # REQUIRED when specifying hostPath, host path to mount into destination
        path: /srv/data/datawave/ingest/
    config:
      name: application-configs
      destination: /microservice-config
      # OPTIONAL specify if the volume is ready only
      readOnly: true
      source:
        type: configmap
        name: application-configs-configmap
    rabbit:
      name: rabbit
      destination: /etc/rabbitmq/
      # OPTIONAL specify if the volume is ready only
      readOnly: true
      source:
        type: configmap
        name: rabbit-configmap
# Feeder definition
feeder:
  image:
    # minikube registry
    registry: "localhost:5000/"
  # Each feeder should be defined within feeds. One deployment per feed will be created
  feeds:
    # feed name
    - name: "mycsv-live"
      # spring profiles to apply to feed1
      profile: "dwv,dwv-mycsv"
      # rabbitmq queue to publish content from feed1
      queue: "live"
    # feed name
    - name: "myjson-live"
      # spring profiles to apply to feed2
      profile: "dwv,dwv-myjson"
      # rabbitmq queue to publish content from feed2
      queue: "live"
  env:
    - name: HADOOP_USER_NAME
      value: datawave
# Ingest definition
ingest:
  init:
    name: "copy-conf"
    image: busybox
    tag: 1.28
    files:
      - /data/config
      - /data/otherConfig
  initContainers:
    - name: "create-ingest-mycsv"
      env:
        - name: HADOOP_USER_NAME
          value: datawave
      image:
        registry: ghcr.io/
        repository: nationalsecurityagency/datawave-stack-hadoop
        tag: 3.3.6
      cmd: ["/bin/bash", "-c", "hadoop fs -mkdir -p hdfs:///datawave/ingest/mycsv"]
      volumes:
        - name: hadoop
          # REQUIRED mount location for hadoop
          destination: /etc/hadoop/conf
          # OPTIONAL specify if the volume is ready only
          readOnly: true
          source:
            # REQUIRED must be one of secret/configmap/hostPath
            type: configmap
            # REQUIRED with type secret or configmap
            name: dwv-hadoop
    - name: "create-ingest-myjson"
      env:
        - name: HADOOP_USER_NAME
          value: datawave
      image:
        registry: ghcr.io/
        repository: nationalsecurityagency/datawave-stack-hadoop
        tag: 3.3.6
      cmd: ["/bin/bash", "-c", "hadoop fs -mkdir -p hdfs:///datawave/ingest/myjson"]
      volumes:
        - name: hadoop
          # REQUIRED mount location for hadoop
          destination: /etc/hadoop/conf
          # OPTIONAL specify if the volume is ready only
          readOnly: true
          source:
            # REQUIRED must be one of secret/configmap/hostPath
            type: configmap
            # REQUIRED with type secret or configmap
            name: dwv-hadoop
  image:
    # minikube registry
    registry: "localhost:5000/"
  # Each ingest pool will create a deployment with replicas
  pools:
    # ingest pool name
    - name: "live"
      # rabbitmq queue to read off of
      queue: "live"
      # number of replcias in the pool
      replicas: 1
      # spring profiles to apply to speedy pool
      profiles: "dwv,dwv-live"
  imagePullSecrets:
    - name: dockerconfigjson-ghcr
  env:
    - name: HADOOP_USER_NAME
      value: datawave
    - name: DATAWAVE_INGEST_HOME
      value: /etc/datawave/conf
#  volumes:
#    - name: dwv-ingest-conf
#      # REQUIRED mount location for hadoop
#      destination: /etc/datawave/conf
#      # OPTIONAL specify if the volume is ready only
#      readOnly: true
#      source:
#        # REQUIRED must be one of secret/configmap/hostPath
#        type: projected
#        # REQUIRED with type secret or configmap
#        maps:
#          - dwv-ingest-ingest-config-configmap
#          -

# Bundler definitions
bundler:
  # true if the bundler is being used
  enabled: false
# if a secret is necessary for bootstrapping define it here.
#### FOR TESTING ONLY. DO NOT USE IN PRODUCTION ####
secrets:
  accumulo:
    # accumulo secret name
    name: accumulo
    # accumulo username value
    username: root
    # accumulo password value
    password: ThisP@ssw0rd1sBANANAS
  keystore:
    name: keystore
    alias: "1"
    password: changeme
    path: "file:///data/certs/keystore.p12"
  truststore:
    name: truststore
    password: ChangeIt
    path: "file:///data/certs/truststore.jks"
  pki:
    name: datawave-certificates-secret
    dir: example-certs
# if configuration is necessary for bootstrapping define it here, specify another named configuration service in global.services.configuration
# configuration.name and messaging.name should match global.services.configuration and global.services.rabbitmq if enabled
configuration:
  enabled: true
  name: ingest-configuration
  dir: example-config
  port: 8888
  replicaCount: 1
  image:
    registry: "ghcr.io/"
    repository: nationalsecurityagency/datawave-config-service
    pullPolicy: IfNotPresent
    tag: 4.0.1
messaging:
  enabled: true
  name: ingest-rabbitmq
  replicaCount: 1
  image:
    repository: rabbitmq
    pullPolicy: IfNotPresent
    tag: 3.11.4-alpine
  ports:
    amqp: 5672
    mgmt: 15672
