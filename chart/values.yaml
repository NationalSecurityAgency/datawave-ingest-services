# global overrides for all microservices
global:
  # OPTIONAL use as a prefix for a registry if in use, otherwise leave blank
  registry: ""
  # External service links
  services:
    # REQUIRED configuration service name/endpoint (all services) this should match configuration.name if built-in configuration is enabled
    configuration: ingest-configuration
    # REQUIRED rabbitmq service name/endpoint for configservice application.yml this should match messaging.name if built-in enabled
    rabbitmq: ingest-rabbitmq
    # REQUIRED zookeeper service name/endpoint for ingest services
    zookeeper: zookeeper
  # Externally defined secret specification
  secrets:
    # REQUIRED accumulo secret
    accumulo:
      # REQUIRED secret name containing accumulo user/password
      name: accumulo
      # REQUIRED username for accumulo user
      username: username
      # REQUIRED password for accumulo user
      password: password
    # REQUIRED keystore secret
    keystore:
      # REQUIRED keystore name
      name: keystore
      # REQUIRED alias key
      alias: alias
      # REQUIRED path key
      path: path
      # REQUIRED password key
      password: password
    # REQUIRED truststore secret
    truststore:
      # REQUIRED keystore name
      name: truststore
      # REQUIRED path key
      path: path
      # REQUIRED password key
      password: password
  # Volume definitions
  volumes:
    # REQUIRED (Feeder/Ingest/Bundler) PKI volume
    pki:
      # PKI volume name
      name: pki
      # REQUIRED mount location for pki
      destination: /data/certs
      # OPTIONAL specify if the volume is ready only
      readOnly: true
      source:
        # REQUIRED must be one of secret/configmap/hostPath
        type: secret
        # REQUIRED with type secret or configmap
        name: datawave-certificates-secret
    # REQUIRED (Feeder/Ingest/Bundler) HADOOP config volume
    hadoop:
      # REQUIRED HADOOP config volume name
      name: hadoop
      # REQUIRED mount location for hadoop
      destination: /etc/hadoop/conf
      # OPTIONAL specify if the volume is ready only
      readOnly: true
      source:
        # REQUIRED must be one of secret/configmap/hostPath
        type: configmap
        # REQUIRED with type secret or configmap
        name: dwv-hadoop
    # REQUIRED (Feeder/Ingest/Bundler) logs volume
    logs:
      # REQUIRED logs mount name
      name: logs
      # REQUIRED mount location for logs
      destination: /logs
      source:
        # REQUIRED must be one of secret/configmap/hostPath
        type: hostPath
        # REQUIRED when specifying hostPath, host path to mount into destination
        path: /srv/logs
    # REQUIRED (Ingest) datawave ingest volume
    datawave:
      # REQUIRED datawave-config name
      name: datawave-conf
      # REQUIRED mount location for datawave-config
      destination: /etc/datawave/conf
      # OPTIONAL specify if the volume is ready only
      readOnly: true
      source:
        # REQUIRED must be one of secret/configmap/hostPath
        type: projected
        maps:
          - dwv-ingest-ingest-config-configmap
          - dwv-ingest-data-types-configmap
          - dwv-all-ingest
    # REQUIRED (Ingest)
    output:
      # REQUIRED Output location volume name
      name: output
      # REQUIRED mount location for output
      destination: /output
      # REQUIRED hdfs prefix for destination
      prefix: "file://"
      source:
        # REQUIRED must be one of secret/configmap/hostPath
        type: hostPath
        # REQUIRED when specifying hostPath, host path to mount into destination
        path: /srv/data/datawave/ingest/
    # REQUIRED (Bundler)
    input:
      # REQUIRED input location volume
      name: input
      # REQUIRED mount location for input
      destination: /input
      source:
        # REQUIRED must be one of secret/configmap/hostPath
        type: hostPath
        # REQUIRED when specifying hostPath, host path to mount into destination
        path: /srv/data/datawave/ingest/
    config:
      name: application-configs
      destination: /microservice-config
      # OPTIONAL specify if the volume is ready only
      readOnly: true
      source:
        type: configmap
        name: application-configs-configmap
    rabbit:
      name: rabbit
      destination: /etc/rabbitmq/
      # OPTIONAL specify if the volume is ready only
      readOnly: true
      source:
        type: configmap
        name: rabbit-configmap
# Feeder definition
feeder:
  # Each feeder should be defined within feeds. One deployment per feed will be created
  feeds:
    # feed name
    - name: "mycsv-live"
      # spring profiles to apply to feed1
      profile: "dwv,dwv-mycsv"
      # rabbitmq queue to publish content from feed1
      queue: "live"
    # feed name
    - name: "myjson-live"
      # spring profiles to apply to feed2
      profile: "dwv,dwv-myjson"
      # rabbitmq queue to publish content from feed2
      queue: "live"
  env:
    - name: HADOOP_USER_NAME
      value: datawave
# Ingest definition
ingest:
  init:
    name: "copy-conf"
    image: busybox
    tag: 1.28
    files:
      - /data/config
      - /data/otherConfig
  initContainers:
#    - name: "copy-configs"
#      image:
#        repository: ghcr.io/nationalsecurityagency/datawave/ingest-kubernetes
#        tag: 7.5.0-SNAPSHOT
#      cmd: ["/bin/bash", "-c", "mkdir -p /local/datawave/conf", "cp /opt/datawave-ingest/current/config/* /local/datawave/conf/"]
    - name: "create-ingest-mycsv"
      env:
        - name: HADOOP_USER_NAME
          value: datawave
      image:
        repository: ghcr.io/nationalsecurityagency/datawave-stack-hadoop
        tag: 3.3.6
      cmd: ["/bin/bash", "-c", "hadoop fs -mkdir -p hdfs:///datawave/ingest/mycsv"]
      volumes:
        - name: hadoop
          # REQUIRED mount location for hadoop
          destination: /etc/hadoop/conf
          # OPTIONAL specify if the volume is ready only
          readOnly: true
          source:
            # REQUIRED must be one of secret/configmap/hostPath
            type: configmap
            # REQUIRED with type secret or configmap
            name: dwv-hadoop
    - name: "create-ingest-myjson"
      env:
        - name: HADOOP_USER_NAME
          value: datawave
      image:
        repository: ghcr.io/nationalsecurityagency/datawave-stack-hadoop
        tag: 3.3.6
      cmd: ["/bin/bash", "-c", "hadoop fs -mkdir -p hdfs:///datawave/ingest/myjson"]
      volumes:
        - name: hadoop
          # REQUIRED mount location for hadoop
          destination: /etc/hadoop/conf
          # OPTIONAL specify if the volume is ready only
          readOnly: true
          source:
            # REQUIRED must be one of secret/configmap/hostPath
            type: configmap
            # REQUIRED with type secret or configmap
            name: dwv-hadoop
  # Each ingest pool will create a deployment with replicas
  pools:
    # ingest pool name
    - name: "live"
      # rabbitmq queue to read off of
      queue: "live"
      # number of replcias in the pool
      replicas: 1
      # spring profiles to apply to speedy pool
      profiles: "dwv,dwv-live"
  env:
    - name: HADOOP_USER_NAME
      value: datawave
    - name: DATAWAVE_INGEST_HOME
      value: /etc/datawave/conf
#  volumes:
#    - name: dwv-ingest-conf
#      # REQUIRED mount location for hadoop
#      destination: /etc/datawave/conf
#      # OPTIONAL specify if the volume is ready only
#      readOnly: true
#      source:
#        # REQUIRED must be one of secret/configmap/hostPath
#        type: projected
#        # REQUIRED with type secret or configmap
#        maps:
#          - dwv-ingest-ingest-config-configmap
#          -

# Bundler definitions
bundler:
  # true if the bundler is being used
  enabled: false
# if a secret is necessary for bootstrapping define it here.
#### FOR TESTING ONLY. DO NOT USE IN PRODUCTION ####
secrets:
  accumulo:
    # accumulo secret name
    name: accumulo
    # accumulo username value
    username: root
    # accumulo password value
    password: ThisP@ssw0rd1sBANANAS
  keystore:
    name: keystore
    alias: "1"
    password: changeme
    path: "file:///data/certs/keystore.p12"
  truststore:
    name: truststore
    password: ChangeIt
    path: "file:///data/certs/truststore.jks"
  pki:
    name: datawave-certificates-secret
    dir: example-certs
# if configuration is necessary for bootstrapping define it here, specify another named configuration service in global.services.configuration
# configuration.name and messaging.name should match global.services.configuration and global.services.rabbitmq if enabled
configuration:
  enabled: true
  name: ingest-configuration
  dir: example-config
  port: 8888
  replicaCount: 1
  image:
    registry: "ghcr.io/"
    repository: nationalsecurityagency/datawave-config-service
    pullPolicy: IfNotPresent
    tag: 4.0.1
messaging:
  enabled: true
  name: ingest-rabbitmq
  replicaCount: 1
  image:
    repository: rabbitmq
    pullPolicy: IfNotPresent
    tag: 3.7.7-alpine
  ports:
    amqp: 5672
    mgmt: 15672
